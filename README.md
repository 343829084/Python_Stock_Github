# Python 量化投资与 Github 使用学习笔记

## 目的

+ 练习 Github 使用
+ 练习 Python + 量化投资技能
+ 作为编程新手，想希望对后来者有帮助

## 如何学习？

本套量化课程由经管之家（原人大经济论坛）的优秀版主 @邢不行 带来，[课程直达链接](http://www.peixun.net/view/866.html)，如果你有学习的意愿可以直接报名课程，本套课程我学习下来，有以下几点感受：

+ 老师毕竟是过来人，思路和重点很清晰，比如就是要带你把 Pandas 玩熟，你就得反复看，越往后学习，越想回来看
+ 老师的技巧是高级的，有些东西你真得学了才知道，比如自动化交易(并不在此代码里面)

## 经验之谈

+ Github　的学习，是编程的基础。成为 Github 专家级的用户。让人更加明确每一步的价值和意义。
+ 只有能够教会别人，才算是真正掌握

## 编程文档讲解

1. news 原来的 Scrapy 爬虫文档，但是因为跨文件调用`from news import ProcessRun` 失败，所以只能放到一个文件夹
    + 这里有个思考点，如何将自己写好的 Python 程序封装?
2. 


## 学习要点

1. 抓数据
    + [X] 预测者网站下载截止目前的最新数据
    + [ ] 通过爬虫抓取，自己维护一份数据库
        - 应该在服务器吗？还是自己的电脑？
        - 维护哪些数据内容？
        - Mongodb？
    + 以上仅为财务数据，应该还有文本数据

2. 玩数据
    + [X] Pandas 基本操作
    + [X] Jieba 分词基本操作

3. 策略
    + 选股策略
    + 择时策略

3. 信号
    + [ ] 如何传递给自动化系统？

4. 自动化交易(Windows 端)
    + 如何进行人工干预?
    

## 不断出现的问题

1. 我自己需要维护一个数据库吗？
    + 预测者网站的数据，加上自己每天爬取的数据
    
2. 因为 Moudle 导入的问题，将文本分析放进了爬虫文件夹，显得不够优雅

## 进一步思考与尝试

+ [X] 增加爬虫爬取网易财经新闻(Scrapy)
    + [ ]根据关键词爬取新闻
        - [ ]Google 搜索
        - [ ]新闻网站
        - [ ]微信相关接口，爬取内容
+ [X] 对新闻内容进行文本分析(jieba 分词)
+ [ ] 增加爬虫数量
    - [ ] 增加爬虫个数
    - [ ] 增加爬虫网站数量
    - [ ] 提升爬虫效率
+ [ ] 增加推荐的精准度，目前就是 `for...in...` 的匹配,这还不够
+ [ ] 如果选出某只股票，可以进入一个系统从以下三个方面给出建议:
    - [ ] 舆情分析是正面比较多还是负面比较多?
    - [ ] 财务数据分析
